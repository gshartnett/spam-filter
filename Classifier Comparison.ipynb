{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## The purpose of this notebook is compare a few classifiers for discrete problems, like spam filtering.\n",
    "## I'll use the data from this website: http://www.aueb.gr/users/ion/data/enron-spam/index.html\n",
    "\n",
    "## import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import scipy.sparse\n",
    "from prettytable import PrettyTable\n",
    "import gc\n",
    "\n",
    "## garbage collection\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## load the data\n",
    "\n",
    "## assemble the file lists\n",
    "spam_file_list1 = ['data/preprocessed/enron1/spam/' + filename for filename in os.listdir('data/preprocessed/enron1/spam')]\n",
    "spam_file_list2 = ['data/preprocessed/enron2/spam/' + filename for filename in os.listdir('data/preprocessed/enron2/spam')]\n",
    "spam_file_list3 = ['data/preprocessed/enron3/spam/' + filename for filename in os.listdir('data/preprocessed/enron3/spam')]\n",
    "spam_file_list4 = ['data/preprocessed/enron4/spam/' + filename for filename in os.listdir('data/preprocessed/enron4/spam')]\n",
    "spam_file_list5 = ['data/preprocessed/enron5/spam/' + filename for filename in os.listdir('data/preprocessed/enron5/spam')]\n",
    "spam_file_list6 = ['data/preprocessed/enron6/spam/' + filename for filename in os.listdir('data/preprocessed/enron6/spam')]\n",
    "spam_file_list = spam_file_list1 + spam_file_list2 + spam_file_list3 + spam_file_list4 + spam_file_list5 + spam_file_list6\n",
    "\n",
    "## assemble the file lists\n",
    "ham_file_list1 = ['data/preprocessed/enron1/ham/' + filename for filename in os.listdir('data/preprocessed/enron1/ham')]\n",
    "ham_file_list2 = ['data/preprocessed/enron2/ham/' + filename for filename in os.listdir('data/preprocessed/enron2/ham')]\n",
    "ham_file_list3 = ['data/preprocessed/enron3/ham/' + filename for filename in os.listdir('data/preprocessed/enron3/ham')]\n",
    "ham_file_list4 = ['data/preprocessed/enron4/ham/' + filename for filename in os.listdir('data/preprocessed/enron4/ham')]\n",
    "ham_file_list5 = ['data/preprocessed/enron5/ham/' + filename for filename in os.listdir('data/preprocessed/enron5/ham')]\n",
    "ham_file_list6 = ['data/preprocessed/enron6/ham/' + filename for filename in os.listdir('data/preprocessed/enron6/ham')]\n",
    "ham_file_list = ham_file_list1 + ham_file_list2 + ham_file_list3 + ham_file_list4 + ham_file_list5 + ham_file_list6\n",
    "\n",
    "## assemble the data\n",
    "ham_data = []\n",
    "for i in range(len(ham_file_list)):\n",
    "  with open(ham_file_list[i], 'r') as myfile:\n",
    "    ham_data.append(myfile.read().replace('\\r\\n',''))\n",
    "\n",
    "spam_data = []\n",
    "for i in range(len(spam_file_list)):\n",
    "  with open(spam_file_list[i], 'r') as myfile:\n",
    "    spam_data.append(myfile.read().replace('\\r\\n',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1655\n",
      "1718\n"
     ]
    }
   ],
   "source": [
    "## drop a fraction of the data (optional, used for building the code)\n",
    "frac = 0.9 #fraction to drop\n",
    "inds = set(random.sample(list(range(len(ham_data))), int(frac*len(ham_data))))\n",
    "ham_data = [n for i,n in enumerate(ham_data) if i not in inds]\n",
    "inds = set(random.sample(list(range(len(spam_data))), int(frac*len(spam_data))))\n",
    "spam_data = [n for i,n in enumerate(spam_data) if i not in inds]\n",
    "\n",
    "print len(ham_data)\n",
    "print len(spam_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## further processing: remove punctuation and numbers, tokenize\n",
    "\n",
    "## define a processing function that 1) lowers the case, 2) tokenizes into words, 3) lemmatizes\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def process(sentence):\n",
    "  return [wordnet_lemmatizer.lemmatize(word.lower()) for word in nltk.word_tokenize(sentence)]\n",
    "\n",
    "## load the list of english stop words\n",
    "stoplist = stopwords.words('english')\n",
    "stoplist.append('subject') #the emails all include a 'subject: XXX' header\n",
    "\n",
    "## set-up regular expressions to delete all non a-z characters\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "\n",
    "## list of punctuation symbols to remove\n",
    "exclude = set(string.punctuation)\n",
    "\n",
    "## list of printable characters\n",
    "printable = set(string.printable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_words = []\n",
    "for i in range(len(spam_data)):\n",
    "  ## remove non-printable characters\n",
    "  text_dummy = filter(lambda x: x in printable, spam_data[i])\n",
    "  ## drop punctuation, tokenize into words, lower the case, and lemmatize\n",
    "  text_dummy = ''.join(ch for ch in text_dummy if ch not in exclude)\n",
    "  words_dummy = process(text_dummy)\n",
    "  ## remove stop words\n",
    "  words_dummy = [w for w in words_dummy if not w in stoplist]\n",
    "  ## remove numbers\n",
    "  words_dummy = [regex.sub('', w) for w in words_dummy if len(regex.sub('', w)) > 0]\n",
    "  \n",
    "  spam_words.append(words_dummy)\n",
    "\n",
    "ham_words = []\n",
    "for i in range(len(ham_data)):\n",
    "  ## remove non-printable characters\n",
    "  text_dummy = filter(lambda x: x in printable, ham_data[i])\n",
    "  ## drop punctuation, tokenize into words, lower the case, and lemmatize\n",
    "  text_dummy = ''.join(ch for ch in text_dummy if ch not in exclude)\n",
    "  words_dummy = process(text_dummy)\n",
    "  ## remove stop words\n",
    "  words_dummy = [w for w in words_dummy if not w in stoplist]\n",
    "  ## remove numbers\n",
    "  words_dummy = [regex.sub('', w) for w in words_dummy if len(regex.sub('', w)) > 0]\n",
    "\n",
    "  ham_words.append(words_dummy)\n",
    "\n",
    "## drop any instances where all the words have been removed\n",
    "spam_words = [ i for i in spam_words if len(i) != 0]\n",
    "ham_words = [ i for i in ham_words if len(i) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## put the data into dataframe form\n",
    "words = spam_words + ham_words\n",
    "classes = [1]*len(spam_words) + [0]*len(ham_words)\n",
    "headers = ['class', 'words']\n",
    "df = pd.DataFrame([classes, words])\n",
    "df = df.transpose()\n",
    "df.columns = headers\n",
    "\n",
    "## shuffle\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "## split off a CV set\n",
    "cvratio = .2 # fraction to split off\n",
    "df_cv = df.copy(deep=True)\n",
    "df_cv = df_cv.iloc[:int(math.floor(cvratio*len(df)))]\n",
    "df_cv = df_cv.reset_index(drop=True)\n",
    "df = df.iloc[int(math.floor(cvratio*len(df))):]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## convert the list of words to a list of word ranks\n",
    "words_tot = [item for sublist in df['words'] for item in sublist]\n",
    "count = Counter(words_tot).most_common()\n",
    "words_unique = [count[i][0] for i in range(len(count))]\n",
    "words_frequencies = [count[i][1] for i in range(len(count))]\n",
    "\n",
    "def word_to_rank(x):\n",
    "  return sorted([ words_unique.index(w) for w in x if w in words_unique])\n",
    "\n",
    "df['word_ranks'] = df['words'].map(word_to_rank)\n",
    "df_cv['word_ranks'] = df_cv['words'].map(word_to_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set statistics:\n",
      "total number of words: 370767\n",
      "total number of unique words: 55042\n",
      "lexical diversity: 0.148454420161\n",
      "\n",
      "\n",
      "+-------------+-------+\n",
      "| Word        | Count |\n",
      "+-------------+-------+\n",
      "| enron       |  4559 |\n",
      "| company     |  2211 |\n",
      "| ect         |  1959 |\n",
      "| ha          |  1508 |\n",
      "| please      |  1443 |\n",
      "| com         |  1410 |\n",
      "| u           |  1311 |\n",
      "| e           |  1271 |\n",
      "| new         |  1255 |\n",
      "| wa          |  1243 |\n",
      "| hou         |  1193 |\n",
      "| may         |  1141 |\n",
      "| would       |  1122 |\n",
      "| said        |  1091 |\n",
      "| time        |  1082 |\n",
      "| price       |   970 |\n",
      "| business    |   918 |\n",
      "| one         |   895 |\n",
      "| information |   890 |\n",
      "| market      |   878 |\n",
      "+-------------+-------+\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEPCAYAAACgFqixAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w8vaiMCJoceCQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb16e5e68d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb16bc44410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## print out some preliminary statistics\n",
    "\n",
    "## lexical diversity\n",
    "def lexical_diversity(tokens):\n",
    "    return 1.0*len(set(tokens))/len(tokens) \n",
    "\n",
    "print 'training set statistics:'\n",
    "print 'total number of words:', len(words_tot)\n",
    "print 'total number of unique words:', len(words_unique)\n",
    "print 'lexical diversity:', lexical_diversity(words_tot)\n",
    "\n",
    "## examine word frequencies\n",
    "print '\\n'\n",
    "pt = PrettyTable(field_names=['Word', 'Count']) \n",
    "[ pt.add_row(kv) for kv in count[:20] ]\n",
    "pt.align['Word'], pt.align['Count'] = 'l', 'r' #set column alignment\n",
    "print pt\n",
    "\n",
    "## get a sense for the frequency distribution of words\n",
    "## what % of words occur with frequency <= x\n",
    "maxwordfreq = [100.0*c*words_frequencies.count(c)/len(words_tot) for c in range(1,50)]\n",
    "for i in range(1,len(maxwordfreq)):\n",
    "  maxwordfreq[i] += maxwordfreq[i-1]\n",
    "%matplotlib inline\n",
    "plt.plot(maxwordfreq, c='black')\n",
    "plt.ylabel('percent of words')\n",
    "plt.xlabel('max word frequency')\n",
    "plt.show()\n",
    "\n",
    "## plot frequency(rank)\n",
    "words_tot_counts = sorted(Counter(words_tot).values(), reverse=True)\n",
    "plt.loglog(words_tot_counts, c='black')\n",
    "plt.ylabel('frequency')\n",
    "plt.xlabel('word rank')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## drop all the words that show up <= p times\n",
    "p = 0\n",
    "if p>0:\n",
    "  K=len(words_tot)\n",
    "  for k in range(len(words_frequencies)):\n",
    "    if words_frequencies[k] == p:\n",
    "      K=k\n",
    "      break\n",
    "\n",
    "  word_ranks_small = []\n",
    "  for i in range(len(df)):\n",
    "    word_ranks_small.append( [w for w in df['word_ranks'].iloc[i] if w < K] )\n",
    "  df['word_ranks_small'] = word_ranks_small\n",
    "\n",
    "  print '% retained:', 100.0*len([item for sublist in df['word_ranks_small'] for item in sublist]) \\\n",
    "   /len([item for sublist in df['word_ranks'] for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## build the bag of words\n",
    "max_rank = len(words_frequencies)\n",
    "Ndocs = len(df)\n",
    "Ndocs_cv = len(df_cv)\n",
    "\n",
    "ranks_tot = [item for sublist in df['word_ranks_small'] for item in sublist]\n",
    "ranks_tot_spam = [item for sublist in df['word_ranks_small'][df['class'] == 1] for item in sublist]\n",
    "ranks_tot_ham = [item for sublist in df['word_ranks_small'][df['class'] == 0] for item in sublist]\n",
    "counter = Counter(ranks_tot)\n",
    "counter_spam = Counter(ranks_tot_spam)\n",
    "counter_ham = Counter(ranks_tot_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV set: correctly classified: 95.690936107 %\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "## Naive Bayes classifier\n",
    "\n",
    "##re-think Laplace smoothing now that I'm ignoring new words in cv set\n",
    "\n",
    "## priors\n",
    "prior_ham = float(sum(df['class']==0))/Ndocs\n",
    "prior_spam = float(sum(df['class']==1))/Ndocs\n",
    "\n",
    "## conditional probabilities of word given class (with Laplace smoothing parameter alpha)\n",
    "alpha = 1 # Laplace smoothing parameter\n",
    "def p_rank_given_spam(rank):\n",
    "  return float(counter_spam[rank] + alpha)/(len(ranks_tot_spam) + alpha*len(ranks_tot))\n",
    "def p_rank_given_ham(rank):\n",
    "  return float(counter_ham[rank] + alpha)/(len(ranks_tot_ham) + alpha*len(ranks_tot))\n",
    "\n",
    "## class prediction\n",
    "def predict(rank_list):\n",
    "  p_spam = math.log(prior_spam) + sum([math.log(p_rank_given_spam(i)) for i in rank_list])\n",
    "  p_ham = math.log(prior_ham) + sum([math.log(p_rank_given_ham(i)) for i in rank_list])\n",
    "  return [p_ham, p_spam].index(max([p_ham, p_spam]))\n",
    "\n",
    "## classification error\n",
    "df_cv['predictions'] = df_cv['word_ranks_small'].map(predict)\n",
    "print 'CV set: correctly classified:', 100*float(sum(df_cv['predictions'] == df_cv['class']))/Ndocs_cv, '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d.o.f. in Nigam: 1.146e+09\n",
      "d.o.f. here: 1.482e+08\n"
     ]
    }
   ],
   "source": [
    "print 'd.o.f. in Nigam:', \"{:.3e}\".format(20101*57000)\n",
    "print 'd.o.f. here:', \"{:.3e}\".format(max_rank*len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################################################################\n",
    "## MaxEnt Classifier\n",
    "\n",
    "## the class assignments as a vector\n",
    "C = np.asarray(df['class'], dtype=float)\n",
    "C_cv = np.asarray(df_cv['class'], dtype=int)\n",
    "\n",
    "## create the features f_w(d), considered as a sparse, integer-valued matrix\n",
    "feature = scipy.sparse.lil_matrix((Ndocs, max_rank))\n",
    "for j in range(Ndocs):\n",
    "  for i in range(len(df['word_ranks'].iloc[j])):\n",
    "    feature[j, df['word_ranks'].iloc[j][i]] += 1.0/(len(df['word_ranks'].iloc[j]))\n",
    "## convert the features into sparse matrices again\n",
    "feature = scipy.sparse.csr_matrix(feature)\n",
    "\n",
    "## create the features f_w(d), considered as a sparse, integer-valued matrix\n",
    "feature_cv = scipy.sparse.lil_matrix((Ndocs_cv, max_rank))\n",
    "for j in range(Ndocs_cv):\n",
    "  for i in range(len(df_cv['word_ranks'].iloc[j])):\n",
    "    feature_cv[j, df_cv['word_ranks'].iloc[j][i]] += 1.0/(len(df_cv['word_ranks'].iloc[j]))\n",
    "## convert the features into sparse matrices again\n",
    "feature_cv = scipy.sparse.csr_matrix(feature_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## useful functions\n",
    "\n",
    "## compute the log likelihood\n",
    "def loglike(lambda_spam, lambda_ham, flambda_spam, flambda_ham):\n",
    "  return flambda_spam.dot(C) + flambda_ham.dot(1-C) - sum(np.log(np.exp(flambda_spam) + np.exp(flambda_ham)))\n",
    "\n",
    "## compute the gradient\n",
    "def gradient(lambda_spam, lambda_ham, flambda_spam, flambda_ham):\n",
    "  boltzmann_spam = np.exp(flambda_spam)\n",
    "  boltzmann_ham = np.exp(flambda_ham)\n",
    "  dLLdlambda_spam = feature.transpose().dot(C) - feature.transpose().dot( (boltzmann_spam/(boltzmann_spam + boltzmann_ham) ) )\n",
    "  dLLdlambda_ham = feature.transpose().dot(1-C) - feature.transpose().dot( (boltzmann_ham/(boltzmann_spam + boltzmann_ham) ) )\n",
    "  return [dLLdlambda_spam, dLLdlambda_ham]\n",
    "\n",
    "## compute gradient via finite differences\n",
    "def gradient_FD(lambda_spam, lambda_ham, flambda_spam, flambda_ham, epsilon):\n",
    "  LL1 = loglike(lambda_spam, lambda_ham, flambda_spam, flambda_ham)\n",
    "  dLLdlambda_spam_FD = [0 for i in range(max_rank)]\n",
    "  dLLdlambda_ham_FD = [0 for i in range(max_rank)]\n",
    "  for i in range(len(lambda_spam)):\n",
    "    lambda_spam_2 = np.copy(lambda_spam)\n",
    "    lambda_ham_2 = np.copy(lambda_ham)\n",
    "    lambda_spam_2[i] += epsilon #update only the spam lambda\n",
    "    flambda_spam_2 = feature.dot(lambda_spam_2)\n",
    "    flambda_ham_2 = feature.dot(lambda_ham_2)\n",
    "    LL2 = loglike(lambda_spam_2, lambda_ham_2, flambda_spam_2, flambda_ham_2)\n",
    "    dLLdlambda_spam_FD[i] = (LL2 - LL1)/epsilon\n",
    "  for i in range(len(lambda_spam)):\n",
    "    lambda_spam_2 = np.copy(lambda_spam)\n",
    "    lambda_ham_2 = np.copy(lambda_ham)\n",
    "    lambda_ham_2[i] += epsilon #update only the ham lambda\n",
    "    flambda_spam_2 = feature.dot(lambda_spam_2)\n",
    "    flambda_ham_2 = feature.dot(lambda_ham_2)\n",
    "    LL2 = loglike(lambda_spam_2, lambda_ham_2, flambda_spam_2, flambda_ham_2)\n",
    "    dLLdlambda_ham_FD[i] = (LL2 - LL1)/epsilon\n",
    "  return [dLLdlambda_spam_FD, dLLdlambda_ham_FD]\n",
    "\n",
    "def predictions(lambda_spam, lambda_ham):\n",
    "  flambda_spam_cv = feature_cv.dot(lambda_spam)\n",
    "  flambda_ham_cv = feature_cv.dot(lambda_ham)\n",
    "  boltzmann_ham_cv = np.squeeze(np.asarray(np.exp(flambda_ham_cv)))\n",
    "  boltzmann_spam_cv = np.squeeze(np.asarray(np.exp(flambda_spam_cv)))\n",
    "  return np.array( boltzmann_spam_cv > boltzmann_ham_cv, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## check gradient (very slow)\n",
    "if False:\n",
    "  ## create the vector of parameters to be learned (initialized randomly)\n",
    "  np.random.seed(seed=1)\n",
    "  lambda_spam = np.random.uniform(0,1,max_rank)\n",
    "  lambda_ham = np.random.uniform(0,1,max_rank)\n",
    "  ## useful factors\n",
    "  flambda_spam = feature.dot(lambda_spam)\n",
    "  flambda_ham = feature.dot(lambda_ham)\n",
    "  ## exact gradient\n",
    "  [dLLdlambda_spam, dLLdlambda_ham] = gradient(lambda_spam, lambda_ham, flambda_spam, flambda_ham)\n",
    "\n",
    "  print 'error in gradients for epsilon = 0.1'\n",
    "  [dLLdlambda_spam_FD, dLLdlambda_ham_FD] = gradient_FD(lambda_spam, lambda_ham, flambda_spam, flambda_ham, 0.1)\n",
    "  print [sum(np.squeeze(np.asarray(dLLdlambda_spam)) - np.asarray(dLLdlambda_spam_FD))/max_rank, \\\n",
    "       sum(np.squeeze(np.asarray(dLLdlambda_ham)) - np.asarray(dLLdlambda_ham_FD))/max_rank]\n",
    "\n",
    "  print 'error in gradients for epsilon = 0.001'\n",
    "  [dLLdlambda_spam_FD, dLLdlambda_ham_FD] = gradient_FD(lambda_spam, lambda_ham, flambda_spam, flambda_ham, 0.001)\n",
    "  print [sum(np.squeeze(np.asarray(dLLdlambda_spam)) - np.asarray(dLLdlambda_spam_FD))/max_rank, \\\n",
    "       sum(np.squeeze(np.asarray(dLLdlambda_ham)) - np.asarray(dLLdlambda_ham_FD))/max_rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Training\n",
    "\n",
    "## learning rate\n",
    "alpha = 10.0\n",
    "\n",
    "## create the vector of parameters to be learned (initialized to zero)\n",
    "lambda_spam = np.zeros(max_rank)\n",
    "lambda_ham = np.zeros(max_rank)\n",
    "## the initial cost and accuracy\n",
    "flambda_spam = feature.dot(lambda_spam)\n",
    "flambda_ham = feature.dot(lambda_ham)\n",
    "## record the log likelihood and the prediction\n",
    "LL_history = [loglike(lambda_spam, lambda_ham, flambda_spam, flambda_ham)]\n",
    "predict = predictions(lambda_spam, lambda_ham)\n",
    "predictions_history = [1.0*sum(predict == C_cv)/len(predict)]\n",
    "\n",
    "## gradient ascent\n",
    "Nitermax = 10000\n",
    "for i in range(Nitermax):\n",
    "  #print 'training:', str(i+1), 'out of', Nitermax\n",
    "  ## compute the gradient\n",
    "  [dLLdlambda_spam, dLLdlambda_ham] = gradient(lambda_spam, lambda_ham, flambda_spam, flambda_ham)\n",
    "  ## advance the parameters\n",
    "  lambda_spam = lambda_spam + alpha*dLLdlambda_spam\n",
    "  lambda_ham = lambda_ham + alpha*dLLdlambda_ham\n",
    "  ## some useful factors\n",
    "  flambda_spam = feature.dot(lambda_spam)\n",
    "  flambda_ham = feature.dot(lambda_ham)\n",
    "  ## record the log likelihood and the predictions\n",
    "  LL_history.append(loglike(lambda_spam, lambda_ham, flambda_spam, flambda_ham)) \n",
    "  predict = predictions(lambda_spam, lambda_ham)\n",
    "  predictions_history.append(1.0*sum(predict == C_cv)/len(predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final prediction accuracy: 0.964338781575\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEPCAYAAAB/WNKuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XucFNWZ//HPA4jIHbmMoFxEBS8gAkpQTBwVBRQviQRk\nE6Nxf4m6MSa76mJW/YnG3YgxbnZN8vMSXU3QmCiogBdApX+KqCDDZQhXhQhmBjCD3IQ4wDz7R9VA\ng9MzDdPV1dP9fb9e/ZqqU9V1nipxnqlzTp0yd0dERCTTGsUdgIiI5CclGBERiYQSjIiIREIJRkRE\nIqEEIyIikVCCERGRSMSeYMxsuJktN7OVZjYuxT7/bWarzGyhmZ2W7RhFROTgxZpgzKwR8CtgGHAK\nMNbMTjxgnxHAce5+AnAd8HDWAxURkYMW9x3MIGCVu3/s7ruAZ4HLDtjnMuB3AO7+PtDGzIqyG6aI\niBysuBPM0cC6pPVPwrLa9vlrDfuIiEiOiTvBiIhInmoSc/1/BbolrR8Tlh24T9c69gHAzDSxmojI\nQXJ3i+K4cd/BzAOON7PuZtYUuBKYcsA+U4DvAJjZYGCzu29IdUB318edu+66K/YYcuGj66BroWtR\n+ydKsd7BuPseM7sRmEGQ7B5392Vmdl2w2R9191fM7CIz+xD4HPhunDGLiEh64m4iw91fA3ofUPbI\nAes3ZjUoERGpt7ibyCQixcXFcYeQE3Qd9tG12EfXIjss6ja4bDIzz6fzERGJmpnhedrJLyIieUoJ\nRkREIqEEIyIikVCCERGRSMQ+TFlEJN+5O5WVlezcuXPvZ8eOHSnXa9t24PrkyZM5+ujcnJ5RCUZE\nCp67s2PHDj7//PP9Ptu3b/9SWaptO3bsqDVJNG7cmCOOOGLvp3nz5mmtt2nThqOOOmq/7cnL7du3\nj/vypaRhyiLSoFQng23btrF161a2bdtW63I6iWLnzp00a9aMFi1a1Php2bJlym3V25s3b15r0mjS\nJDf/no9ymLISjIhkRVVVFVu3bmXLli1s3rx572fLli11Jonk5W3btnH44YfTqlUrWrduTatWrb60\nXL3esmXL/ZJDqkTRvHlzGjduHPclioUSTJqUYESis2fPnv2SQnKSSKds+/bttGjRgrZt2+73ad26\ndY3JIdVyy5Ytc/ZuoCFSgkmTEoxI3dydbdu2UVFRQUVFBZs2bfrSck1lW7dupVWrVrRr1+5LSaJN\nmzZ1lrVq1apg7xJymRJMmpRgpBDt2bOHiooKNm7cuN/n008/3W+5Olls2rSJZs2a0b59e9q3b8+R\nRx75peWaytq2basEkYeUYNKkBCP5orKykvXr11NWVkZ5eTkbNmxImTw2b95M27Zt6dSp036fjh07\n7l3u0KHDfgmjadOmcZ+i5AglmDQpwUiu++KLLygvL6e8vHxv8kherv65ZcsWOnXqRJcuXejcuTNF\nRUUUFRV9KXF06tSJ9u3b685CDpkSTJqUYCROu3btoqysjHXr1rF27dr9flZ/tm7dSlFR0d7Ekepn\nhw4dlDQkK5Rg0qQEI1HauXMna9asYfXq1axZs4a1a9ful0g2btxIp06d6NatG127dt37M3m5Q4cO\nNGqkGZokdyjBpEkJRuqjqqqK9evXs3r16ho/mzZtokePHvTs2ZNjjz2Wbt267ZdEunTpwmGHHRb3\naYgcFCWYNCnBSDoqKipYsWLFfp+VK1eyZs0aWrduTc+ePWv8dOnSRXcfknfyMsGYWTvgj0B34C/A\naHffUsN+fwG2AFXALncfVMsxlWAECIbufvTRRyxduvRLyWTXrl307t37S5/jjjuOFi1axB26SFbl\na4KZAFS4+/1mNg5o5+631bDfamCgu3+WxjGVYAqMu1NeXk5paSlLliyhtLSU0tJSli9fTqdOnTjl\nlFO+lEiKioowi+T/J5EGJ18TzHLgHHffYGZHAQl3P7GG/dYAp7t7RRrHVILJY7t27WLp0qWUlJRQ\nUlLC4sWLKS0tpXHjxvTt25e+ffvSp08f+vbty8knn0zr1q3jDlkk5+Vrgtnk7kemWk8qXw1sBvYA\nj7r7Y7UcUwkmT1RWVrJkyRJKSkqYP38+8+fPZ8mSJXTv3p2BAwfSv39/+vXrR9++fSkqKoo7XJEG\nK8oEE+mMcWY2E0j+v98AB+6oYfdUmWGIu5ebWUdgppktc/fZGQ5VYuTurFu3jnfffZc5c+bw7rvv\nsmTJEnr27MmAAQMYOHAg3/rWt+jXrx+tWrWKO1wRSVOkCcbdL0i1zcw2mFlRUhPZxhTHKA9/fmpm\nLwCDgJQJZvz48XuXi4uLKS4uPrTgJTKVlZWUlJTsTSZz5sxh9+7dnHnmmZx55pn84he/YMCAAepw\nF4lAIpEgkUhkpa64O/k3ufuEVJ38ZtYcaOTu282sBTADuNvdZ6Q4pprIctCuXbuYN28es2bNIpFI\n8N5773H88cdz1lln7U0qPXv2VMe7SAzytQ/mSOBPQFfgY4JhypvNrDPwmLuPNLNjgRcIms+aAE+7\n+321HFMJJgdUVVVRUlLCG2+8waxZs5gzZw7HHXcc5557Lueeey5f/epXadu2bdxhigh5mmCioAQT\nn4qKCqZPn86rr77K9OnT6dChA0OHDuXcc8/lnHPO4cgjvzR+Q0RygBJMmpRgssfdWbBgAdOmTePV\nV19l6dKlFBcXM2LECEaMGEH37t3jDlFE0qAEkyYlmGhVVVUxZ84cJk+ezOTJk2nSpAmXXXYZF110\nEWeffTaHH3543CGKyEFqsMOUpeHbs2cPiUSC559/nhdffJFOnTrxjW98g6lTp9KnTx91zItISkow\n8iXuzqJFi5g4cSJ/+MMfOOqooxgzZgxvvfUWJ5xwQtzhiUgDoQQje33yySdMnDiRiRMnsn37dr79\n7W/z+uuvc9JJJ8Udmog0QOqDKXB79uxh+vTpPPLII7z99tuMGjWKq666iiFDhmhqepECoD4Yybiy\nsjIef/xxfvvb39KpUyeuu+46nn76aVq2bBl3aCKSJ5RgCszChQt58MEHmTp1KqNHj+aFF15gwIAB\ncYclInlIbSAFoKqqildeeYXzzz+fiy++mJNPPpnVq1fzyCOPKLmISGR0B5PHqqqqmDRpEvfccw+N\nGzfm5ptvZsyYMTRt2jTu0ESkACjB5KHqxHL33XfTvHlzJkyYwIgRI/TMiohklRJMHnF3pk6dyu23\n384RRxzB/fffr8QiIrFRgskT8+fP55ZbbmHjxo1MmDCBiy++WIlFRGKlTv4Gbt26dVx11VVccskl\njB07lkWLFjFy5EglFxGJnRJMA7Vr1y4eeOAB+vfvT48ePVixYgXf//73adJEN6Uikhv026gBeued\nd7j++uvp0qXL3rdDiojkGiWYBmT79u3ccsstTJ06lQcffJDRo0erKUxEcpaayBqIt99+m379+lFZ\nWcnSpUsZM2aMkouI5DTdweS4v//979xxxx0888wzPPzww1x66aVxhyQikpbY7mDMbJSZLTGzPWaW\ncr4SMxtuZsvNbKWZjctmjHH76KOPOOuss1izZg2LFy9WchGRBiXOJrJS4OvA/0+1g5k1An4FDANO\nAcaa2YnZCS9ekyZN4swzz+Taa6/l+eefp0OHDnGHJCJyUGJrInP3FQBWe0fCIGCVu38c7vsscBmw\nPPoI47F7925uvfVWXnzxRV5++WXOOOOMuEMSETkkud4HczSwLmn9E4Kkk5c+++wzRo8eTZMmTSgp\nKaFdu3ZxhyQicsgiTTBmNhMoSi4CHLjd3adGUef48eP3LhcXF1NcXBxFNRm3atUqLrnkEoYPH84D\nDzygByZFJBKJRIJEIpGVumJ/ZbKZzQJudveSGrYNBsa7+/Bw/TbA3X1CimM1yFcmz549myuuuIJ7\n7rmH6667Lu5wRKSAFMIrk1Od3DzgeDPrDpQDVwJjsxZVFrz88stcc801TJw4kWHDhsUdjohIxsQ5\nTPlyM1sHDAammdmrYXlnM5sG4O57gBuBGcCfgWfdfVlcMWfaM888w7XXXsuUKVOUXEQk78TeRJZJ\nDamJ7NFHH+Wee+7htddeo0+fPnGHIyIFqhCayArKE088wU9/+lMSiYQmqhSRvKUEk2UTJ07kzjvv\n5M0331RyEZG8pgSTRZMmTeLWW2/l9ddfp3fv3nGHIyISKfXBZMnbb7/NFVdcwYwZMzjttNPiDkdE\nBIi2D0bT9WfBsmXLGDVqFE8//bSSi4gUDCWYiK1fv56LLrqICRMmcMEFF8QdjohI1qiJLEKVlZUU\nFxdz4YUX7jeFjYhIroiyiUwJJkI33HAD5eXlTJ48mUaNdLMoIrlHz8E0QE888QSzZs1i7ty5Si4i\nUpB0BxOBkpIShg0bxltvvcVJJ50UdzgiIilpFFkD8vnnnzN27FgeeughJRcRKWi6g8mw73//+3zx\nxRc89dRTscYhIpIO9cE0EJMmTeKNN95g4cKFcYciIhI73cFkyIYNGzj11FN56aWXGDx4cCwxiIgc\nLA1TTlOcCWbMmDH06NGDCRNqfNmmiEhOUhNZjpsyZQolJSU8+eSTcYciIpIzdAdTT1u2bKFPnz78\n/ve/p7i4OKt1i4jUl5rI0hRHgrnpppvYuXMnjz32WFbrFRHJBDWR5aglS5bw7LPPsmzZsrhDERHJ\nObE9aGlmo8xsiZntMbMBtez3FzNbZGYLzGxuNmOsjbvz4x//mDvvvJP27dvHHY6ISM5JeQdjZg8B\nKdub3P2metZdCnwdeKSO/aqAYnf/rJ71ZdRLL73E+vXrueGGG+IORUQkJ9V2B/MBMB9oBgwAVoWf\n04Cm9a3Y3Ve4+yqgrrY/qyPOrKusrOTmm2/ml7/8JU2aqJVRRKQmKX87uvtTAGZ2A3C2u+8O1x8G\n3s5OeEEowEwz2wM86u6x96Y//vjjnHDCCQwdOjTuUEREclY6f363A1oDm8L1lmFZncxsJlCUXESQ\nMG5396lpxjjE3cvNrCNBolnm7rNT7Zz8Yq/i4uKMDx3euXMn9957L1OmTMnocUVEsiGRSJBIJLJS\nV53DlM3su8B4YBZBgvgaML76DqfeAZjNAm5295I09r0L2ObuD6bYHvkw5QceeIB3332XSZMmRVqP\niEg2xP4cjJkdBXyF4O5jrruvz1gAQYK5xd3n17CtOdDI3bebWQtgBnC3u89IcaxIE8zWrVs54YQT\nmDVrFieffHJk9YiIZEsuvA9mEPBVgruXMzJRsZldbmbrgMHANDN7NSzvbGbTwt2KgNlmtgB4D5ia\nKrlkw29+8xuGDh2q5CIikoZ0msjuI0gqT4dFY4F57v5vEcd20KK8g/n73//Osccey4wZM+jbt28k\ndYiIZFvcT/JfBJzm7lVhME8BC4CcSzBReuqppzj99NOVXERE0pTuQxxt2TeKrE1EseSs3bt3c//9\n9+stlSIiByGdBPMzYEHYGV89iuy2SKPKMZMmTaJz586cffbZcYciItJgpDuKrDP7OvczOoosk6Lq\ngznzzDMZN24cl19+ecaPLSISp7j7YCBILl8Llx1I9yHJBq+kpISysjIuueSSuEMREWlQ6hymHI4i\n+xGwNPzcZGb/EXVgueLXv/41119/PY0bN447FBGRBiWdYcqL2X8UWWNggbufmoX4Dkqmm8g2bdrE\ncccdx8qVK+nYsWPGjisikity4UHLtknLBTOK7IknnmDkyJFKLiIih0CjyFJwdx599FENTRYROUR1\nJhh3/4OZJdg3imxcro4iy6R3332Xxo0bM3jw4LhDERFpkNJtImsE/A3YDPQys6/VsX+D9+STT3LN\nNddgFknTpIhI3kunk38CMAb4M8HriwHc3S+NOLaDlqlO/h07dnDMMcdQWlrK0UcfnYHIRERyU9zP\nwVwO9Hb3L6IIIBe9+OKLDBo0SMlFRKQe0mkiWw0cFnUgueSpp57i6quvjjsMEZEGLWUTmZk9RPDU\n/tFAP+ANYO9djLvflI0AD0Ymmsg2btxIr169KCsro3nz5hmKTEQkN8XVRPZB+HM+UDAvoJ88eTIj\nRoxQchERqaeUCcbdC/IBkOeee44f/OAHcYchItLg1dZE9id3H21mpQRNZfvJx6liqpvHysvLOeKI\nIzIYmYhIboqriexH4c+RUVSci6qbx5RcRETqL+UoMncvD39+XNOnvhWb2f1mtszMFprZJDNrnWK/\n4Wa23MxWmtm4+tZbm+eee45vfvObUVYhIlIwamsi28a+prHq2ycPl93da0wIaVdsNhR4092rwlcC\nuLv/5IB9GgErgfOBMmAecKW7L09xzENuItu0aRM9evRg/fr16uAXkYIRSxOZu7eKosKk47+etPoe\ncEUNuw0CVlXfMZnZs8BlQI0Jpj6mT59OcXGxkouISIakNReZmZ1tZt8NlzuY2bEZjuNa4NUayo8G\n1iWtfxKWZdy0adO4+OKLozi0iEhBqnOqGDO7Czgd6A38D9AUmAgMSeO7M4Gi5CKCZrbb3X1quM/t\nwC53f+ago6/B+PHj9y4XFxdTXFxc53d2797Na6+9xoQJEzIRgohIzkokEiQSiazUlc5klwuB/kCJ\nu/cPyxZnYpiymV0DfA84r6a5zsxsMDDe3YeH67cR9NXUmAkOtQ9m9uzZ/PCHP2TBggUH/V0RkYYs\n7jdaVoa/tT0MpkUmKjaz4cCtwKW1TKQ5DzjezLqbWVPgSiKYVWDatGmMHFkwo7FFRLIinQTzJzN7\nBGhrZt8DXgd+m4G6HwJaAjPNrMTMfgNgZp3NbBqAu+8BbgRmELwu4Fl3X5aBuvej/hcRkcyrs4kM\nwMwuAC4k6EOZ7u4zow7sUBxKE1lZWRl9+vTh008/pXHjxhFFJiKSm2J9H4yZjXD3V4GZSWXXu/vD\nUQSUbW+++SbFxcVKLiIiGZZOE9mdZnZe9YqZ/SvBsyh54Y033uD888+POwwRkbyTziiyDsA0gg75\n4cCJwFh3r4w+vINzsE1k7k737t2ZOXMmvXv3jjAyEZHcFGsTmbv/zcwuJejcnw+MysiL73PAhx9+\nSFVVFb169Yo7FBGRvJMywSTNRVb9cGRToCcwKrxTqNdcZLmgunnMLJLkLSJS0GKbiywXvPHGG1xy\nySVxhyEikpdqm035RHdfbmYDatru7iWRRnYIDqYPxt0pKirigw8+oFu3bhFHJiKSm+Lqg7mZYBqX\nX9SwzYHzaihvMD788EOaNWum5CIiEpHamsi+F/48N3vhZM8777zDkCF1ztcpIiKHqLZO/m/U9kV3\nn5z5cLJn9uzZSjAiIhGqrYmstt5vBxp0gnnnnXe48cYb4w5DRCRvpTUXWUORbid/RUUFPXv2ZNOm\nTZoiRkQKWtzT9eedOXPm8JWvfEXJRUQkQgWZYNT/IiISvYJMMO+//z6DBw+OOwwRkbyWzmSXNY0m\n2wKUuvvGSKI6ROn0wVRVVdG2bVvWrFlD+/btsxSZiEhuinWyS+AfgTOBWeF6McGkl8ea2T3u/vso\nAovKypUr6dixo5KLiEjE0kkwTYCT3H0DgJkVAb8DvgK8BTSoBPPBBx9w+umnxx2GiEjeS6cPpmt1\ncgltDMs2AbuiCSs6SjAiItmRzh1MwsymAc+F66PCshbA5kOt2MzuJ3iY8wvgI+C77r61hv3+QtDn\nUwXscvdBh1onBAnmssvy5oWcIiI5K51OfgO+AZwdFr0DTKrvS8fMbCjwprtXmdl9gLv7T2rYbzUw\n0N0/S+OYtYa1e/du2rZtS1lZGa1bN/jX2YiI1Fvcb7R0M5sNVBJMETM3E2+0dPfXk1bfA65IsauR\noeHUy5Yt45hjjlFyERHJgjp/cZvZaGAuQdPYaOB9MxuV4TiuBV5Nsc2BmWY2z8y+V59KPvjgAwYO\nHFifQ4iISJrS6YO5HTij+pkXM+sIvA48X9cXzWwmUJRcRJAwbnf3qeE+txP0rTyT4jBD3L08rHem\nmS1z99mp6hw/fvze5eLiYoqLi/euL1q0iP79+9cVtohI3kokEiQSiazUlU4fTKm7901abwQsSi47\n5MrNriF4qdl57v5FGvvfBWxz9wdTbK+19e68885j3LhxDBs27BAjFhHJL3E/aPmamU0H/hCujwFe\nqW/FZjYcuBX4WqrkYmbNgUbuvj0ctXYhcPeh1OfuLF68mFNPPfWQYxYRkfSlNV2/mV0BVM8O+ba7\nv1Dvis1WAU2BirDoPXf/JzPrDDzm7iPN7FjgBYJmtSbA0+5+Xy3HTHkHU15ezqmnnsrGjRsJBsaJ\niEjcdzC4+yRgUiYrdvcTUpSXAyPD5TXAaZmob/HixfTt21fJRUQkS2p7ZfI2gjuHL20iGL3coMb6\nqnlMRCS7UiYYd2+VzUCiVlpaut+IMhERiVbBvA+muolMRESyI61O/oYiVSf/rl27aN26NRUVFTRv\n3jyGyEREclOUnfwFcQezcuVKunbtquQiIpJFBZFgli9fzkknnRR3GCIiBaVgEsyJJ54YdxgiIgWl\nIBLMihUrlGBERLKsIBLM8uXL6d27d9xhiIgUlLwfRebutGnThjVr1tC+ffuYIhMRyU0aRVYP5eXl\nNGvWTMlFRCTL8j7BqINfRCQeeZ9g1MEvIhKPvE8w6uAXEYlHQSQY3cGIiGRf3ieYlStX0qtXr7jD\nEBEpOHk9TLmyspJWrVqxbds2mjZtGmNkIiK5ScOUD9HatWvp0qWLkouISAzyOsF89NFH9OzZM+4w\nREQKUmwJxszuMbNFZrbAzF4zs6NS7DfczJab2UozG3cwdaxevZrjjjsuMwGLiMhBifMO5n537+fu\n/YGXgbsO3MHMGgG/AoYBpwBjzSztIWEfffSREoyISExiSzDuvj1ptQVQVcNug4BV7v6xu+8CngUu\nS7eO1atXq4lMRCQmTeKs3MzuBb4DbAbOrWGXo4F1SeufECSdtOgORkQkPpEmGDObCRQlFwEO3O7u\nU939DuCOsG/lh8D4+tY5fnxwCHdn5cqVuoMREUmSSCRIJBJZqSsnnoMxs67AK+7e94DywcB4dx8e\nrt8GuLtPSHGcvc/BbNy4kZNOOomKiopogxcRacDy8jkYMzs+afVyYFkNu80Djjez7mbWFLgSmJLO\n8dX/IiISrzj7YO4zs14EnfsfA9cDmFln4DF3H+nue8zsRmAGQTJ83N1rSkRfoiHKIiLxii3BuPuo\nFOXlwMik9deAg54Oec2aNfTo0eOQ4xMRkfrJ2yf5165dS/fu3eMOQ0SkYOV1gunWrVvcYYiIFCwl\nGBERiUReJhh3Z+3atXTt2jXuUEREClZeJpgtW7ZgZrRp0ybuUEREClZeJpjq5jGzSJ4dEhGRNOR1\nghERkfgowYiISCSUYEREJBJ5m2A0gkxEJF55mWDWrVunOxgRkZjlZYJRE5mISPxy4n0wmWJmvnv3\nbo444gi2b99O06ZN4w5JRCSn5eX7YKLy6aef0rZtWyUXEZGY5V2CKSsro0uXLnGHISJS8PIuwZSX\nl9O5c+e4wxARKXh5l2B0ByMikhuUYEREJBJ5l2DURCYikhtiSzBmdo+ZLTKzBWb2mpkdlWK/vyTt\nN7eu4+oORkQkN8R5B3O/u/dz9/7Ay8BdKfarAordvb+7D6rroOXl5UowIiI5ILYE4+7bk1ZbECSS\nmhgHEWdZWZmayEREckCsT/Kb2b3Ad4DNwLnuXlHDPqvD7XuAR939sVqO502aNGHHjh0cdthhUYUt\nIpI3onySv0kUB61mZjOBouQiwIHb3X2qu98B3GFm44AfAuNrOMwQdy83s47ATDNb5u6zU9XZtGlT\n/v3f/x2A4uJiiouLM3MyIiJ5IJFIkEgkslJXTsxFZmZdgVfcvW8d+90FbHP3B1Ns9379+rFw4cIo\nwhQRyTt5OReZmR2ftHo5sKyGfZqbWctwuQVwIbCktuOqg19EJDdE2kRWh/vMrBdB5/7HwPUAZtYZ\neMzdRxI0r71gZk4Q69PuPqO2g6qDX0QkN8SWYNx9VIrycmBkuLwGOO1gjqsEIyKSG/LuSf6ioqK6\ndxIRkcjlXYLp1KlT3CGIiAh5mGA6duwYdwgiIkIeJhjdwYiI5AYlGBERiUROPGiZKWbmu3fvpnHj\nxnGHIiLSIOTlg5ZRUXIREckNeZdgREQkNyjBiIhIJJRgREQkEkowIiISCSUYERGJhBKMiIhEQglG\nREQioQQjIiKRUIIREZFIKMGIiEgklGBERCQSsScYM7vZzKrM7MgU24eb2XIzW2lm47Idn4iIHJpY\nE4yZHQNcAHycYnsj4FfAMOAUYKyZnZi9CBuuRCIRdwg5QddhH12LfXQtsiPuO5j/BG6tZfsgYJW7\nf+zuu4BngcuyElkDp/+BAroO++ha7KNrkR2xJRgzuxRY5+6ltex2NLAuaf2TsExERHJckygPbmYz\ngaLkIsCBO4B/I2geS94mIiJ5IpY3WppZH+B1YAdBYjkG+CswyN03Ju03GBjv7sPD9dsAd/cJKY6b\nP6/nFBHJkqjeaJkTr0w2szXAAHf/7IDyxsAK4HygHJgLjHX3ZdmPUkREDkbcnfzVnLCJzMw6m9k0\nAHffA9wIzAD+DDyr5CIi0jDkxB2MiIjkn1y5g6mXQngY08yOMbM3zezPZlZqZjeF5e3MbIaZrTCz\n6WbWJuk7PzGzVWa2zMwuTCofYGaLw+v1yzjOp77MrJGZlZjZlHC9UK9DGzN7Ljy3P5vZVwr4Wvyz\nmS0Jz+NpM2taSNfCzB43sw1mtjipLGPnH17PZ8PvvGtm3eoMyt0b9IcgSX4IdAcOAxYCJ8YdVwTn\neRRwWrjckqBv6kRgAvCvYfk44L5w+WRgAcFIwR7hNaq+Y30fOCNcfgUYFvf5HcL1+GdgIjAlXC/U\n6/Ak8N1wuQnQphCvBdAFWA00Ddf/CFxdSNcCOBs4DVicVJax8wduAH4TLo8h6LKoNaZ8uIMpiIcx\n3X29uy8Ml7cDywhG310GPBXu9hRwebh8KcE/gN3u/hdgFTDIzI4CWrn7vHC/3yV9p0EIZ4C4CPht\nUnEhXofWwFfd/X8AwnPcQgFei1BjoIWZNQGOIBiZWjDXwt1nA58dUJzJ808+1vMEg69qlQ8JpuAe\nxjSzHgT/pzumAAAHb0lEQVR/qbwHFLn7BgiSENAp3O3A6/LXsOxogmtUrSFer+oZIJI7EAvxOhwL\n/M3M/idsLnzUzJpTgNfC3cuAXwBrCc5ri7u/TgFeiwN0yuD57/2OBwOwNqeaQ7JaPiSYgmJmLQn+\nevhReCdz4CiNvB61YWYXAxvCu7naxu7n9XUINQEGAL929wHA58BtFNi/CQAza0vwF3Z3guayFmb2\nLQrwWtQhk+df57Mz+ZBg/gokdzZVP7SZd8Jb/+eB37v7S2HxBjMrCrcfBVQ/qPpXoGvS16uvS6ry\nhmIIcKmZrQb+AJxnZr8H1hfYdYDgr8t17v5BuD6JIOEU2r8JgKHAanffFP51/QJwFoV5LZJl8vz3\nbrPgGcXW7r6ptsrzIcHMA443s+5m1hS4EpgSc0xReQJY6u7/lVQ2BbgmXL4aeCmp/Mpw5MexwPHA\n3PA2eYuZDTIzA76T9J2c5+7/5u7d3L0nwX/rN939KmAqBXQdAMKmj3Vm1issOp/gebGC+jcRWgsM\nNrNm4TmcDyyl8K6Fsf+dRSbPf0p4DIBvAm/WGU3cIx8yNHpiOMGoqlXAbXHHE9E5DgH2EIySWwCU\nhOd9JMG0OysIHkhtm/SdnxCMDlkGXJhUPhAoDa/Xf8V9bvW4JuewbxRZQV4HoB/BH1kLgckEo8gK\n9VrcFZ7XYoLO6MMK6VoAzwBlwBcECfe7QLtMnT9wOPCnsPw9oEddMelBSxERiUQ+NJGJiEgOUoIR\nEZFIKMGIiEgklGBERCQSSjAiIhIJJRgREYmEEow0SGa2pnoeJDObXY/jXB0+4ZwTzKyfmY1IsW1g\n9fTpZnaOmZ2ZwXq7m9nYmuoSOVRKMJIzwukn0rX3AS53P7se1V5Dbk1meBrBTNFf4u7z3f3H4Wox\nwVQoaavj+h4L/EOKukQOiRKMZIWZ3WnBS+HeMrNnzOxfwvJZZvafZjYXuMnMRprZe2Y2P3xRUsdw\nvyPDFyaVmtljJE2HYWbbkpZvMbO5ZrbQzO4Ky7qb2dJwtuElZvaamR1uZlcApwMTw9mIDz8g5v8T\nHmuBBS/1ahaWfzOMY4GZJcKyRmb287B8oZn9ICwfYGYJM5tnZq8mzQs1y8zuM7P3w+syxMwOA+4B\nRofxfPOAeM4xs6lm1h24HvhxuN8QM+tgZs+Hx3u/+u7GzO4ys9+Fd3m/C6/FW2b2QfgZHB7+Z8DZ\n4fF+VF1XeIx2ZvaCmS0yszlm1ifp2I+H5/Khmf0wLG9uZtPC67P4wPOQAhL39Ab65P+H4Jd4CcHU\nHS2BlcC/hNtmAb9K2rdN0vI/Aj8Pl/8LuCNcvohg2pwjw/Wt4c8LgEfCZSOYn+xsghl2K4G+4bY/\nAv+QVH//FHG3S1r+KfCDcHkx0Dlcbh3+vJ5gGo3q2THaEsx2/A7QPiwbDTyeVG/1uY0AZobLVwP/\nnSKe5Klx7qq+huH608BZ4XJXgjnrqvebx74XcTVLWj4emHfgsWuo67+BO8Plc4EFSceeHZ5ne+Bv\nBO9k+Ub1f4dwv1Zx/xvUJ55PE0SiNwR4yYMXwu2q/ss4yR+Tlrua2Z+AzgQJaU1Y/jXg6wDu/oqZ\nHfhiJYALgQvMrIQgwbQATiB4h8Uady8N95tP8Ba/aqmmHe9rZvcSJIsWwPSwfDbwVBjn5LBsKPD/\n3IPfqO6+2cxOAfoAM8OJAxsRzBVVrfq78wmSYH0MBU4K6wFoacG7YSBIFJXhclPgV2Z2GkGSPiGN\nY59NkDRw91nh3WTLcNvL7r4bqDCzDUARwTxWD5jZz8Lth9xHJg2bEozkgs+Tlh8CHnD3l83sHIK/\nkmtSU1Iw4Gfu/th+hUGT0hdJRXsI/pKvy5PApe6+xMyuJvirHnf/JzM7AxgJzDezgbXEuMTdh6TY\nXh3THur//6IBXwmT+L7CIN8kX99/Bta7+6lhn8zOetabfF2rgCbuvsrMBhDcad5rZq+7+731rEca\nIPXBSDa8A1wS9nu0JPjFnEpr9v2Vf3VS+VvAtwAsGGXVNmlbdbKZDlxrZi3C/bpU9+GQ+i5lW1hn\nTVoSvGfmsOq6w+P2dPd57n4Xwfs1jgFmAteFv7Qxs3YEM9h2rO7nMLMmZnZyirqq46stntringH8\nKCnGfim+1wYoD5e/Q9CkVX28Vim+8zbw7fC4xcDfPHjZXY3MrDOw092fAX5O8I4aKUBKMBI5D16I\nNQVYBLxM0IexpXrzAbvfDTxvZvOATw8o/5qZlRK8I3xtchVhPTMJpix/18wWA88RJIma6qn2JPBw\nTZ38wJ3AXIJfsMuSyn8edl4vBua4+2LgtwRNcYvNbAEwNrybGAVMMLPq1yxUDy1O9abFWcDJNXXy\nH2Aq8PXqTn7gJuD0sCN+CXBdiu/9BrgmjLEX++5uFgNVYcf8jw74znhgoJktAv6DIDHVpPoc+gJz\nwzr+L6C7lwKl6folK8yshbt/bmZHENyNfM+D1x6LSJ5SH4xky6Nh89DhwJNKLiL5T3cwIiISCfXB\niIhIJJRgREQkEkowIiISCSUYERGJhBKMiIhEQglGREQi8b84SnPpDmJU2AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb16e5e6910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEPCAYAAABsj5JaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkSR1YgKRJHViApEkdWICkSR18v8B0Wwp5gjnrhUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb16b786d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## predictions \n",
    "print 'final prediction accuracy:', predictions_history[-1]\n",
    "#print LL_history;\n",
    "## plot the training history\n",
    "%matplotlib inline\n",
    "plt.plot(LL_history[500:], c='black')\n",
    "plt.ylabel('log likelihood')\n",
    "plt.xlabel('gradient ascent iterations')\n",
    "plt.show()\n",
    "\n",
    "## plot the training history\n",
    "%matplotlib inline\n",
    "plt.plot(predictions_history, c='black')\n",
    "plt.ylabel('prediction % accuracy')\n",
    "plt.xlabel('gradient ascent iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#xxxxxxxxxxxxxxxxxxxxxx OLD CODE xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################################################################\n",
    "## MaxEnt Classifier (CAN I SPEED THIS UP?)\n",
    "## simple idea: don't evaluate error each iteration\n",
    "\n",
    "## the class assignments as a vector\n",
    "C = np.asarray(df['class'], dtype=float)\n",
    "C_cv = np.asarray(df_cv['class'], dtype=int)\n",
    "\n",
    "## create the features f_w(d), considered as a sparse, integer-valued matrix\n",
    "feature = scipy.sparse.lil_matrix((Ndocs, max_rank))\n",
    "for j in range(Ndocs):\n",
    "  for i in range(len(df['word_ranks'].iloc[j])):\n",
    "    feature[j, df['word_ranks'].iloc[j][i]] += 1.0/(len(df['word_ranks'].iloc[j]))\n",
    "\n",
    "## create the features f_w(d), considered as a sparse, integer-valued matrix for the CV set\n",
    "feature_cv = scipy.sparse.lil_matrix((Ndocs_cv, max_rank)).toarray()\n",
    "for j in range(Ndocs_cv):\n",
    "  for i in range(len(df_cv['word_ranks'].iloc[j])):\n",
    "    feature_cv[j, df_cv['word_ranks'].iloc[j][i]] += 1.0/(len(df['word_ranks'].iloc[j]))\n",
    "    \n",
    "## convert the features into sparse matrices again\n",
    "feature = scipy.sparse.csr_matrix(feature)\n",
    "feature_cv = scipy.sparse.csr_matrix(feature_cv)\n",
    "\n",
    "## some useful arrays\n",
    "CC = np.array([C,]*max_rank).transpose()\n",
    "II = np.ones(CC.shape)\n",
    "cc = np.array([C,]*1).transpose()\n",
    "ii = np.array([np.ones(len(C)),]*1).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## useful functions\n",
    "\n",
    "## compute the log likelihood\n",
    "def loglike(lambda_spam, lambda_ham, flambda_spam, flambda_ham):\n",
    "  return sum( np.multiply(cc,flambda_spam) + np.multiply(ii-cc,flambda_ham) - np.log( np.exp( flambda_spam ) + np.exp( flambda_ham ) ) )[0,0]\n",
    "\n",
    "## compute the gradient\n",
    "def gradient(lambda_spam, lambda_ham, flambda_spam, flambda_ham):\n",
    "  boltzmann_spam = np.exp(flambda_spam)\n",
    "  boltzmann_ham = np.exp(flambda_ham)\n",
    "  dLLdlambda_spam = (feature.multiply(CC) - (feature.multiply(boltzmann_spam)/(boltzmann_spam + boltzmann_ham))).sum(axis=0)\n",
    "  dLLdlambda_ham = (feature.multiply(II-CC) - (feature.multiply(boltzmann_ham)/(boltzmann_spam + boltzmann_ham))).sum(axis=0)\n",
    "  return [dLLdlambda_spam, dLLdlambda_ham]\n",
    "\n",
    "## compute gradient via finite differences\n",
    "def gradient_FD(lambda_spam, lambda_ham, flambda_spam, flambda_ham, epsilon):\n",
    "  LL1 = loglike(lambda_spam, lambda_ham, flambda_spam, flambda_ham)\n",
    "  dLLdlambda_spam_FD = [0 for i in range(max_rank)]\n",
    "  dLLdlambda_ham_FD = [0 for i in range(max_rank)]\n",
    "  for i in range(len(lambda_spam)):\n",
    "    lambda_spam_2 = np.copy(lambda_spam)\n",
    "    lambda_ham_2 = np.copy(lambda_ham)\n",
    "    lambda_spam_2[i] += epsilon #update only the spam lambda\n",
    "    flambda_spam_2 = feature.multiply(lambda_spam_2).sum(axis=1)\n",
    "    flambda_ham_2 = feature.multiply(lambda_ham_2).sum(axis=1)\n",
    "    LL2 = loglike(lambda_spam_2, lambda_ham_2, flambda_spam_2, flambda_ham_2)\n",
    "    dLLdlambda_spam_FD[i] = (LL2 - LL1)/epsilon\n",
    "  for i in range(len(lambda_spam)):\n",
    "    lambda_spam_2 = np.copy(lambda_spam)\n",
    "    lambda_ham_2 = np.copy(lambda_ham)\n",
    "    lambda_ham_2[i] += epsilon #update only the ham lambda\n",
    "    flambda_spam_2 = feature.multiply(lambda_spam_2).sum(axis=1)\n",
    "    flambda_ham_2 = feature.multiply(lambda_ham_2).sum(axis=1)\n",
    "    LL2 = loglike(lambda_spam_2, lambda_ham_2, flambda_spam_2, flambda_ham_2)\n",
    "    dLLdlambda_ham_FD[i] = (LL2 - LL1)/epsilon\n",
    "  return [dLLdlambda_spam_FD, dLLdlambda_ham_FD]\n",
    "\n",
    "def predictions(lambda_spam, lambda_ham):\n",
    "  flambda_spam_cv = feature_cv.multiply(lambda_spam).sum(axis=1)\n",
    "  flambda_ham_cv = feature_cv.multiply(lambda_ham).sum(axis=1)\n",
    "  boltzmann_ham_cv = np.squeeze(np.asarray(np.exp(flambda_ham_cv)))\n",
    "  boltzmann_spam_cv = np.squeeze(np.asarray(np.exp(flambda_spam_cv)))\n",
    "  return np.array( boltzmann_spam_cv > boltzmann_ham_cv, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## check gradient (very slow)\n",
    "if True:\n",
    "  ## create the vector of parameters to be learned (initialized randomly)\n",
    "  np.random.seed(seed=1)\n",
    "  lambda_spam = np.random.uniform(0,1,max_rank)\n",
    "  lambda_ham = np.random.uniform(0,1,max_rank)\n",
    "  \n",
    "  ## useful factors\n",
    "  flambda_spam = feature.multiply(lambda_spam).sum(axis=1)\n",
    "  flambda_ham = feature.multiply(lambda_ham).sum(axis=1)\n",
    "  ## exact gradient\n",
    "  [dLLdlambda_spam, dLLdlambda_ham] = gradient(lambda_spam, lambda_ham, flambda_spam, flambda_ham)\n",
    "\n",
    "  print 'error in gradients for epsilon = 0.1'\n",
    "  [dLLdlambda_spam_FD, dLLdlambda_ham_FD] = gradient_FD(lambda_spam, lambda_ham, flambda_spam, flambda_ham, 0.1)\n",
    "  print [sum(np.squeeze(np.asarray(dLLdlambda_spam)) - np.asarray(dLLdlambda_spam_FD))/max_rank, \\\n",
    "       sum(np.squeeze(np.asarray(dLLdlambda_ham)) - np.asarray(dLLdlambda_ham_FD))/max_rank]\n",
    "\n",
    "  print 'error in gradients for epsilon = 0.001'\n",
    "  [dLLdlambda_spam_FD, dLLdlambda_ham_FD] = gradient_FD(lambda_spam, lambda_ham, flambda_spam, flambda_ham, 0.001)\n",
    "  print [sum(np.squeeze(np.asarray(dLLdlambda_spam)) - np.asarray(dLLdlambda_spam_FD))/max_rank, \\\n",
    "       sum(np.squeeze(np.asarray(dLLdlambda_ham)) - np.asarray(dLLdlambda_ham_FD))/max_rank]\n",
    "\n",
    "  print sum(np.squeeze(np.asarray(dLLdlambda_spam)))\n",
    "  print sum(np.asarray(dLLdlambda_spam_FD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Training\n",
    "\n",
    "## learning rate\n",
    "alpha = 10.0\n",
    "\n",
    "## create the vector of parameters to be learned (initialized to zero)\n",
    "lambda_spam = np.zeros(max_rank)\n",
    "lambda_ham = np.zeros(max_rank)\n",
    "\n",
    "## the initial cost and accuracy\n",
    "flambda_spam = feature.multiply(lambda_spam).sum(axis=1)\n",
    "flambda_ham = feature.multiply(lambda_ham).sum(axis=1)\n",
    "## record the log likelihood and the prediction\n",
    "LL_history = [loglike(lambda_spam, lambda_ham, flambda_spam, flambda_ham)]\n",
    "predict = predictions(lambda_spam, lambda_ham)\n",
    "predictions_history = [1.0*sum(predict == C_cv)/len(predict)]\n",
    "\n",
    "## gradient ascent\n",
    "Nitermax = 2\n",
    "for i in range(Nitermax):\n",
    "  print 'training:', str(i+1), 'out of', Nitermax\n",
    "  ## compute the gradient\n",
    "  [dLLdlambda_spam, dLLdlambda_ham] = gradient(lambda_spam, lambda_ham, flambda_spam, flambda_ham)\n",
    "  ## advance the parameters\n",
    "  lambda_spam = lambda_spam + alpha*dLLdlambda_spam\n",
    "  lambda_ham = lambda_ham + alpha*dLLdlambda_ham\n",
    "  ## reshape\n",
    "  lambda_spam = np.squeeze(np.asarray(lambda_spam))\n",
    "  lambda_ham = np.squeeze(np.asarray(lambda_ham))\n",
    "  ## some useful factors\n",
    "  flambda_spam = feature.multiply(lambda_spam).sum(axis=1)\n",
    "  flambda_ham = feature.multiply(lambda_ham).sum(axis=1)\n",
    "\n",
    "  ## record the log likelihood and the predictions\n",
    "  LL_history.append(loglike(lambda_spam, lambda_ham, flambda_spam, flambda_ham)) \n",
    "  predict = predictions(lambda_spam, lambda_ham)\n",
    "  predictions_history.append(1.0*sum(predict == C_cv)/len(predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## predictions \n",
    "print 'final prediction accuracy:', predictions_history[-1]\n",
    "#print LL_history;\n",
    "## plot the training history\n",
    "%matplotlib inline\n",
    "plt.plot(LL_history, c='black')\n",
    "plt.ylabel('log likelihood')\n",
    "plt.xlabel('gradient ascent iterations')\n",
    "plt.show()\n",
    "\n",
    "## plot the training history\n",
    "%matplotlib inline\n",
    "plt.plot(predictions_history, c='black')\n",
    "plt.ylabel('prediction % accuracy')\n",
    "plt.xlabel('gradient ascent iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### OLDER VERSIONS\n",
    "## MaxEnt Classifier\n",
    "## if I end up dropping some low freq. words I might need to be careful\n",
    "## worry about possible empty documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## learning rate\n",
    "alpha = 0.1\n",
    "\n",
    "## create the vector of parameters to be learned (initialized to zero)\n",
    "lambda_spam = np.ones(len(words_frequencies))\n",
    "lambda_ham = np.ones(len(words_frequencies))\n",
    "\n",
    "## the class assignments as a vector\n",
    "C = np.asarray(df['class'], dtype=float)\n",
    "C_cv = np.asarray(df_cv['class'], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## useful intermediate quantities\n",
    "flambda_spam = [sum([ lambda_spam[r]*df['word_ranks'].iloc[b].count(r)/len(df['word_ranks'].iloc[b]) for r in df['word_ranks'].iloc[b]]) for b in range(len(df))]\n",
    "flambda_ham = [sum([ lambda_ham[r]*df['word_ranks'].iloc[b].count(r)/len(df['word_ranks'].iloc[b]) for r in df['word_ranks'].iloc[b]]) for b in range(len(df))]\n",
    "boltzmann_spam = np.exp(flambda_spam)\n",
    "boltzmann_ham = np.exp(flambda_ham)\n",
    "## record the log likelihood\n",
    "LL = sum( C*(flambda_spam) + (1-C)*(flambda_ham) - np.log(np.exp(flambda_spam) + np.exp(flambda_ham)))\n",
    "LL_history = [LL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dldlambda_spam = np.ones(len(words_frequencies))\n",
    "dldlambda_ham = np.ones(len(words_frequencies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for r in range(3):\n",
    "  dldlambda_spam[r] = sum([lambda_spam[r]*C[b]/len(df['word_ranks'].iloc[b]) for b in range(len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "butt = sum([lambda_spam[0]*C[b]/len(df['word_ranks'].iloc[b]) for b in range(len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## compute the gradient\n",
    "dldlambda_spam = (feature.multiply(CC) - feature.multiply(boltzmann_spam)/(boltzmann_spam + boltzmann_ham)).sum(axis=0)\n",
    "dldlambda_ham = (feature.multiply(II-CC) - feature.multiply(boltzmann_ham)/(boltzmann_spam + boltzmann_ham)).sum(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## advance the parameters\n",
    "lambda_spam = lambda_spam + alpha*dldlambda_spam\n",
    "lambda_ham = lambda_ham + alpha*dldlambda_ham "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################################################################\n",
    "## MaxEnt Classifier (CAN I SPEED THIS UP?)\n",
    "\n",
    "## the class assignments as a vector\n",
    "C = np.asarray(df['class'], dtype=float)\n",
    "C_cv = np.asarray(df_cv['class'], dtype=int)\n",
    "\n",
    "## some useful matrices\n",
    "CC = np.array([C,]*len(words_tot_unique)).transpose()\n",
    "II = np.ones(CC.shape)\n",
    "\n",
    "## create the features f_w(d), considered as a sparse, integer-valued matrix\n",
    "feature = scipy.sparse.csr_matrix((len(df), len(words_tot_unique))).toarray()\n",
    "for j in range(len(df)):\n",
    "  for i in range(len(df['words2'].iloc[j])):\n",
    "    feature[j, words_tot_unique.index(df['words2'].iloc[j][i])] += 1.0/(len(df['words2'].iloc[j]))\n",
    "\n",
    "## create the features f_w(d), considered as a sparse, integer-valued matrix for the CV set\n",
    "feature_cv = scipy.sparse.csr_matrix((len(df_cv), len(words_tot_unique))).toarray()\n",
    "for j in range(len(df_cv)):\n",
    "  for i in range(len(df_cv['words2'].iloc[j])):\n",
    "    if df_cv['words2'].iloc[j][i] in words_tot_unique:\n",
    "      feature_cv[j, words_tot_unique.index(df_cv['words2'].iloc[j][i])] += 1.0/(len(df_cv['words2'].iloc[j]))\n",
    "\n",
    "## convert the features into sparse matrices again\n",
    "feature = scipy.sparse.csr_matrix(feature)\n",
    "feature_cv = scipy.sparse.csr_matrix(feature_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Training\n",
    "\n",
    "## learning rate\n",
    "alpha = 0.1\n",
    "\n",
    "## create the vector of parameters to be learned (initialized to zero)\n",
    "lambda_spam = np.zeros(len(words_tot_unique))\n",
    "lambda_ham = np.zeros(len(words_tot_unique))\n",
    "\n",
    "## the initial cost and accuracy\n",
    "## first some useful Boltzmann factors\n",
    "flambda_s = feature.multiply(lambda_spam).sum(axis=1)\n",
    "flambda_h = feature.multiply(lambda_ham).sum(axis=1)\n",
    "boltzmann_spam = np.exp(flambda_s)\n",
    "boltzmann_ham = np.exp(flambda_h)\n",
    "## record the log likelihood\n",
    "LL = sum( (C*np.squeeze(np.asarray((flambda_s)))) + ((1-C)*np.squeeze(np.asarray((flambda_h)))) \\\n",
    "           - np.log( np.exp( flambda_s ) + np.exp( flambda_h ) ) )[0,0]\n",
    "LL_history = [LL]\n",
    "## then the prediction\n",
    "flambda_s_cv = feature_cv.multiply(lambda_spam).sum(axis=1)\n",
    "flambda_h_cv = feature_cv.multiply(lambda_ham).sum(axis=1)\n",
    "boltzmann_ham_cv = np.squeeze(np.asarray(np.exp(flambda_h_cv)))\n",
    "boltzmann_spam_cv = np.squeeze(np.asarray(np.exp(flambda_s_cv)))\n",
    "predictions = np.array( boltzmann_spam_cv > boltzmann_ham_cv, dtype=int)\n",
    "predictions_history = [1.0*sum(predictions == C_cv)/len(predictions)]\n",
    "\n",
    "## gradient ascent\n",
    "Nitermax = 200\n",
    "for i in range(Nitermax):\n",
    "  print 'training:', str(i+1), 'out of', Nitermax\n",
    "  ## compute the gradient\n",
    "  dldlambda_spam = (feature.multiply(CC) - feature.multiply(boltzmann_spam)/(boltzmann_spam + boltzmann_ham)).sum(axis=0)\n",
    "  dldlambda_ham = (feature.multiply(II-CC) - feature.multiply(boltzmann_ham)/(boltzmann_spam + boltzmann_ham)).sum(axis=0) \n",
    "  ## advance the parameters\n",
    "  lambda_spam = lambda_spam + alpha*dldlambda_spam\n",
    "  lambda_ham = lambda_ham + alpha*dldlambda_ham\n",
    "  ## reshape\n",
    "  lambda_spam = np.squeeze(np.asarray(lambda_spam))\n",
    "  lambda_ham = np.squeeze(np.asarray(lambda_ham))\n",
    "  \n",
    "  ## some useful Boltzmann factors\n",
    "  flambda_s = feature.multiply(lambda_spam).sum(axis=1)\n",
    "  flambda_h = feature.multiply(lambda_ham).sum(axis=1)\n",
    "  boltzmann_spam = np.exp(flambda_s)\n",
    "  boltzmann_ham = np.exp(flambda_h)\n",
    "  ## record the log likelihood\n",
    "  LL = sum( (C*np.squeeze(np.asarray((flambda_s)))) + ((1-C)*np.squeeze(np.asarray((flambda_h)))) \\\n",
    "           - np.log( np.exp( flambda_s ) + np.exp( flambda_h ) ) )[0,0]\n",
    "  LL_history.append(LL)\n",
    "  \n",
    "  ## predictions \n",
    "  flambda_s_cv = feature_cv.multiply(lambda_spam).sum(axis=1)\n",
    "  flambda_h_cv = feature_cv.multiply(lambda_ham).sum(axis=1)\n",
    "  boltzmann_ham_cv = np.squeeze(np.asarray(np.exp(flambda_h_cv)))\n",
    "  boltzmann_spam_cv = np.squeeze(np.asarray(np.exp(flambda_s_cv)))\n",
    "  predictions = np.array( boltzmann_spam_cv > boltzmann_ham_cv, dtype=int)\n",
    "  predictions_history.append(1.0*sum(predictions == C_cv)/len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## predictions \n",
    "print 'final prediction accuracy:', predictions_history[-1]\n",
    "\n",
    "## plot the training history\n",
    "%matplotlib inline\n",
    "plt.plot(LL_history, c='black')\n",
    "plt.ylabel('log likelihood')\n",
    "plt.xlabel('gradient ascent iterations')\n",
    "plt.show()\n",
    "\n",
    "## plot the training history\n",
    "%matplotlib inline\n",
    "plt.plot(predictions_history, c='black')\n",
    "plt.ylabel('prediction % accuracy')\n",
    "plt.xlabel('gradient ascent iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## OLD MaxEnt Classifier -- attempt w/ sparse arrays (very slow)\n",
    "\n",
    "## the class assignments as a vector\n",
    "C = np.asarray(df['class'], dtype=float)\n",
    "C_cv = np.asarray(df_cv['class'], dtype=int)\n",
    "\n",
    "## create the features f_w(d), considered as a sparse, integer-valued matrix\n",
    "feature = scipy.sparse.csr_matrix((len(df), len(words_tot_unique))).toarray()\n",
    "for j in range(len(df)):\n",
    "  for i in range(len(df['words2'].iloc[j])):\n",
    "    feature[j, words_tot_unique.index(df['words2'].iloc[j][i])] += 1.0/(len(df['words2'].iloc[j]))\n",
    "\n",
    "## create the features f_w(d), considered as a sparse, integer-valued matrix for the CV set\n",
    "feature_cv = scipy.sparse.csr_matrix((len(df_cv), len(words_tot_unique))).toarray()\n",
    "for j in range(len(df_cv)):\n",
    "  for i in range(len(df_cv['words2'].iloc[j])):\n",
    "    if df_cv['words2'].iloc[j][i] in words_tot_unique:\n",
    "      feature_cv[j, words_tot_unique.index(df_cv['words2'].iloc[j][i])] += 1.0/(len(df_cv['words2'].iloc[j]))\n",
    "      \n",
    "## create the matrices of parameters to be learned    \n",
    "lambda_spam = np.zeros(len(words_tot_unique))\n",
    "lambda_ham = np.zeros(len(words_tot_unique))\n",
    "\n",
    "## some useful matrices\n",
    "CC = np.array([C,]*len(words_tot_unique)).transpose()\n",
    "II = np.ones(CC.shape)\n",
    "\n",
    "## learning rate\n",
    "alpha = 0.0001\n",
    "\n",
    "## initial log likelihood\n",
    "LL = sum( C*(lambda_spam * feature).sum(axis=1) + (1-C)*(lambda_ham * feature).sum(axis=1) - \\\n",
    "         np.log( np.exp((lambda_spam * feature).sum(axis=1)) + np.exp((lambda_ham * feature).sum(axis=1)) ) )\n",
    "print 'initial log likelihood:', LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## training\n",
    "LL_history = [LL]\n",
    "Nitermax = 5\n",
    "for i in range(Nitermax):\n",
    "  print 'training:', str(i), 'out of', Nitermax\n",
    "  ## some useful Boltzmann factors\n",
    "  boltzmann_ham = np.exp((lambda_ham * feature).sum(axis=1))\n",
    "  boltzmann_ham = np.array([boltzmann_ham,]*len(words_tot_unique)).transpose()\n",
    "  ## convert them to the right size\n",
    "  boltzmann_spam = np.exp((lambda_spam * feature).sum(axis=1))\n",
    "  boltzmann_spam = np.array([boltzmann_spam,]*len(words_tot_unique)).transpose()\n",
    "  ## compute the gradient\n",
    "  dldlambda_spam = (CC*feature - (boltzmann_spam * feature)/(boltzmann_spam + boltzmann_ham)).sum(axis=0)\n",
    "  dldlambda_ham = ((II-CC)*feature - (boltzmann_ham * feature)/(boltzmann_spam + boltzmann_ham)).sum(axis=0)\n",
    "  ## advance the parameters\n",
    "  lambda_spam = lambda_spam + alpha*dldlambda_spam\n",
    "  lambda_ham = lambda_ham + alpha*dldlambda_ham\n",
    "  ## record the log likelihood\n",
    "  LL = sum( C*(lambda_spam * feature).sum(axis=1) + (1-C)*(lambda_ham * feature).sum(axis=1) - \\\n",
    "         np.log( np.exp((lambda_ham * feature).sum(axis=1)) + np.exp((lambda_spam * feature).sum(axis=1)) ) )\n",
    "  LL_history.append(LL)\n",
    "  \n",
    "  LL = sum( C*(lambda_spam * feature).sum(axis=1) + (1-C)*(lambda_ham * feature).sum(axis=1) - \\\n",
    "         np.log( np.exp((lambda_ham * feature).sum(axis=1)) + np.exp((lambda_spam * feature).sum(axis=1)) ) )\n",
    "print 'final log likelihood:', LL\n",
    "\n",
    "## plot the training history\n",
    "%matplotlib inline\n",
    "plt.plot(LL_history, c='black')\n",
    "plt.ylabel('log likelihood')\n",
    "plt.xlabel('gradient ascent iterations')\n",
    "plt.show()\n",
    "\n",
    "## predictions \n",
    "boltzmann_ham = np.exp((lambda_ham * feature_cv).sum(axis=1))\n",
    "boltzmann_spam = np.exp((lambda_spam * feature_cv).sum(axis=1))\n",
    "predictions = np.array( boltzmann_spam > boltzmann_ham, dtype=int)\n",
    "print 'CV set: correctly classified:', 1.0*sum(predictions == C_cv)/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## some useful arrays\n",
    "#CC = np.array([C,]*max_rank).transpose()\n",
    "#II = np.ones(CC.shape)\n",
    "#cc = np.array([C,]*1).transpose()\n",
    "#ii = np.array([np.ones(len(C)),]*1).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## convert the list of words to a list of word ranks\n",
    "words_tot = [item for sublist in df['words'] for item in sublist]\n",
    "count = Counter(words_tot).most_common()\n",
    "words_unique = [count[i][0] for i in range(len(count))]\n",
    "words_frequencies = [count[i][1] for i in range(len(count))]\n",
    "\n",
    "word_ranks = []\n",
    "for i in range(len(df)):\n",
    "  word_ranks_dummy = sorted([ words_unique.index(w) for w in df['words'].iloc[i]])\n",
    "  word_ranks.append(word_ranks_dummy)\n",
    "df['word_ranks'] = word_ranks\n",
    "\n",
    "## do the same for the CV set, but only include words that show up in the training data\n",
    "## otherwise we'd be comparing apples & oranges\n",
    "word_ranks = []\n",
    "for i in range(len(df_cv)):\n",
    "  word_ranks_dummy = sorted([words_unique.index(w) for w in df_cv['words'].iloc[i] if w in words_unique])\n",
    "  word_ranks.append(word_ranks_dummy)\n",
    "df_cv['word_ranks'] = word_ranks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2, Gavin",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
